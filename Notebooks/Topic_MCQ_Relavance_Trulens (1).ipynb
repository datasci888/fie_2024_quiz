{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3d18d190",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3d18d190",
        "outputId": "6a202b25-9605-4882-b828-db0fbbef15a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-24.0\n",
            "Collecting trulens_eval\n",
            "  Downloading trulens_eval-0.28.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.1.19-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from trulens_eval) (1.25.2)\n",
            "Requirement already satisfied: frozendict>=2.3.8 in /usr/local/lib/python3.10/dist-packages (from trulens_eval) (2.4.4)\n",
            "Collecting munch>=3.0.0 (from trulens_eval)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting dill>=0.3.7 (from trulens_eval)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from trulens_eval) (4.66.4)\n",
            "Requirement already satisfied: nltk>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from trulens_eval) (3.8.1)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from trulens_eval) (2.31.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from trulens_eval) (1.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from trulens_eval) (4.11.0)\n",
            "Collecting psutil>=5.9.8 (from trulens_eval)\n",
            "  Downloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: pip>=24.0 in /usr/local/lib/python3.10/dist-packages (from trulens_eval) (24.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.10/dist-packages (from trulens_eval) (24.0)\n",
            "Collecting python-dotenv>=1.0.0 (from trulens_eval)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.10/dist-packages (from trulens_eval) (2.7.1)\n",
            "Collecting merkle-json>=1.0.0 (from trulens_eval)\n",
            "  Downloading merkle_json-1.0.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting langchain-core>=0.1.6 (from trulens_eval)\n",
            "  Downloading langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting typing-inspect>=0.8.0 (from trulens_eval)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting millify>=0.1.1 (from trulens_eval)\n",
            "  Downloading millify-0.1.1.tar.gz (1.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: humanize>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from trulens_eval) (4.7.0)\n",
            "Collecting streamlit>=1.32.2 (from trulens_eval)\n",
            "  Downloading streamlit-1.34.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting streamlit-aggrid==0.3.4 (from trulens_eval)\n",
            "  Downloading streamlit_aggrid-0.3.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting streamlit-extras>=0.4.0 (from trulens_eval)\n",
            "  Downloading streamlit_extras-0.4.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting streamlit-pills>=0.3.0 (from trulens_eval)\n",
            "  Downloading streamlit_pills-0.3.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: rich>=13.6.0 in /usr/local/lib/python3.10/dist-packages (from trulens_eval) (13.7.1)\n",
            "Requirement already satisfied: sqlalchemy>=2.0.19 in /usr/local/lib/python3.10/dist-packages (from trulens_eval) (2.0.30)\n",
            "Collecting alembic>=1.11.2 (from trulens_eval)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from streamlit-aggrid==0.3.4->trulens_eval) (2.0.3)\n",
            "Collecting python-decouple<4.0,>=3.6 (from streamlit-aggrid==0.3.4->trulens_eval)\n",
            "  Downloading python_decouple-3.8-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.6-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.38 (from langchain)\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.56-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting Mako (from alembic>=1.11.2->trulens_eval)\n",
            "  Downloading Mako-1.3.3-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core>=0.1.6->trulens_eval)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting packaging>=23.2 (from trulens_eval)\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.1->trulens_eval) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.1->trulens_eval) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.1->trulens_eval) (2023.12.25)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->trulens_eval) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->trulens_eval) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->trulens_eval) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->trulens_eval) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->trulens_eval) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->trulens_eval) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.6.0->trulens_eval) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.6.0->trulens_eval) (2.16.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=2.0.19->trulens_eval) (3.0.3)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.32.2->trulens_eval) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit>=1.32.2->trulens_eval) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.32.2->trulens_eval) (5.3.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.32.2->trulens_eval) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.32.2->trulens_eval) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.32.2->trulens_eval) (14.0.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.32.2->trulens_eval) (0.10.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit>=1.32.2->trulens_eval)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit>=1.32.2->trulens_eval)\n",
            "  Downloading pydeck-0.9.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.32.2->trulens_eval) (6.3.3)\n",
            "Collecting watchdog>=2.1.5 (from streamlit>=1.32.2->trulens_eval)\n",
            "  Downloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl.metadata (37 kB)\n",
            "Requirement already satisfied: entrypoints>=0.4 in /usr/local/lib/python3.10/dist-packages (from streamlit-extras>=0.4.0->trulens_eval) (0.4)\n",
            "Collecting htbuilder>=0.6.2 (from streamlit-extras>=0.4.0->trulens_eval)\n",
            "  Downloading htbuilder-0.6.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting markdownlit>=0.0.5 (from streamlit-extras>=0.4.0->trulens_eval)\n",
            "  Downloading markdownlit-0.0.7-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: prometheus-client>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit-extras>=0.4.0->trulens_eval) (0.20.0)\n",
            "Collecting st-annotated-text>=3.0.0 (from streamlit-extras>=0.4.0->trulens_eval)\n",
            "  Downloading st_annotated_text-4.0.1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting streamlit-camera-input-live>=0.2.0 (from streamlit-extras>=0.4.0->trulens_eval)\n",
            "  Downloading streamlit_camera_input_live-0.2.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting streamlit-card>=0.0.4 (from streamlit-extras>=0.4.0->trulens_eval)\n",
            "  Downloading streamlit_card-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting streamlit-embedcode>=0.1.2 (from streamlit-extras>=0.4.0->trulens_eval)\n",
            "  Downloading streamlit_embedcode-0.1.2-py3-none-any.whl.metadata (414 bytes)\n",
            "Collecting streamlit-faker>=0.0.2 (from streamlit-extras>=0.4.0->trulens_eval)\n",
            "  Downloading streamlit_faker-0.0.3-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting streamlit-image-coordinates<0.2.0,>=0.1.1 (from streamlit-extras>=0.4.0->trulens_eval)\n",
            "  Downloading streamlit_image_coordinates-0.1.6-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting streamlit-keyup>=0.1.9 (from streamlit-extras>=0.4.0->trulens_eval)\n",
            "  Downloading streamlit_keyup-0.2.4-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting streamlit-toggle-switch>=1.0.2 (from streamlit-extras>=0.4.0->trulens_eval)\n",
            "  Downloading streamlit_toggle_switch-1.0.2-py3-none-any.whl.metadata (395 bytes)\n",
            "Collecting streamlit-vertical-slider>=2.5.5 (from streamlit-extras>=0.4.0->trulens_eval)\n",
            "  Downloading streamlit_vertical_slider-2.5.5-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting validators>=0.20.0 (from streamlit-extras>=0.4.0->trulens_eval)\n",
            "  Downloading validators-0.28.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->trulens_eval)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=1.32.2->trulens_eval) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=1.32.2->trulens_eval) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=1.32.2->trulens_eval) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.32.2->trulens_eval)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from htbuilder>=0.6.2->streamlit-extras>=0.4.0->trulens_eval) (10.1.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core>=0.1.6->trulens_eval)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.6.0->trulens_eval) (0.1.2)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from markdownlit>=0.0.5->streamlit-extras>=0.4.0->trulens_eval) (3.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from markdownlit>=0.0.5->streamlit-extras>=0.4.0->trulens_eval) (4.9.4)\n",
            "Collecting favicon (from markdownlit>=0.0.5->streamlit-extras>=0.4.0->trulens_eval)\n",
            "  Downloading favicon-0.7.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting pymdown-extensions (from markdownlit>=0.0.5->streamlit-extras>=0.4.0->trulens_eval)\n",
            "  Downloading pymdown_extensions-10.8.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->streamlit-aggrid==0.3.4->trulens_eval) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->streamlit-aggrid==0.3.4->trulens_eval) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->streamlit-aggrid==0.3.4->trulens_eval) (2024.1)\n",
            "Collecting faker (from streamlit-faker>=0.0.2->streamlit-extras>=0.4.0->trulens_eval)\n",
            "  Downloading Faker-25.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from streamlit-faker>=0.0.2->streamlit-extras>=0.4.0->trulens_eval) (3.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.11.2->trulens_eval) (2.1.5)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.32.2->trulens_eval)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.32.2->trulens_eval) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.32.2->trulens_eval) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.32.2->trulens_eval) (0.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2->streamlit-aggrid==0.3.4->trulens_eval) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from favicon->markdownlit>=0.0.5->streamlit-extras>=0.4.0->trulens_eval) (4.12.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.4.0->trulens_eval) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.4.0->trulens_eval) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.4.0->trulens_eval) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.4.0->trulens_eval) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.4.0->trulens_eval) (3.1.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.7.0->favicon->markdownlit>=0.0.5->streamlit-extras>=0.4.0->trulens_eval) (2.5)\n",
            "Downloading trulens_eval-0.28.2-py3-none-any.whl (751 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m751.3/751.3 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit_aggrid-0.3.4-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.1.19-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Downloading langsmith-0.1.56-py3-none-any.whl (120 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m120.8/120.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading merkle_json-1.0.0-py3-none-any.whl (5.2 kB)\n",
            "Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading streamlit-1.34.0-py2.py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m116.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit_extras-0.4.2-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m70.5/70.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit_pills-0.3.0-py3-none-any.whl (706 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m706.3/706.3 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading htbuilder-0.6.2-py3-none-any.whl (12 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading markdownlit-0.0.7-py3-none-any.whl (15 kB)\n",
            "Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.0-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m102.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_decouple-3.8-py3-none-any.whl (9.9 kB)\n",
            "Downloading st_annotated_text-4.0.1-py3-none-any.whl (9.0 kB)\n",
            "Downloading streamlit_camera_input_live-0.2.0-py3-none-any.whl (6.6 kB)\n",
            "Downloading streamlit_card-1.0.0-py3-none-any.whl (680 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m680.8/680.8 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit_embedcode-0.1.2-py3-none-any.whl (3.5 kB)\n",
            "Downloading streamlit_faker-0.0.3-py3-none-any.whl (14 kB)\n",
            "Downloading streamlit_image_coordinates-0.1.6-py3-none-any.whl (6.3 kB)\n",
            "Downloading streamlit_keyup-0.2.4-py3-none-any.whl (7.4 kB)\n",
            "Downloading streamlit_toggle_switch-1.0.2-py3-none-any.whl (635 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m635.4/635.4 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit_vertical_slider-2.5.5-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading validators-0.28.1-py3-none-any.whl (39 kB)\n",
            "Downloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.3-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Downloading Faker-25.1.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading favicon-0.7.0-py2.py3-none-any.whl (5.9 kB)\n",
            "Downloading pymdown_extensions-10.8.1-py3-none-any.whl (250 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m250.8/250.8 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: millify\n",
            "  Building wheel for millify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for millify: filename=millify-0.1.1-py3-none-any.whl size=1844 sha256=754879e3a0881fd5c49d854c9c8cd1cf3a9cb4ab5dadbfeebe8bca56cf8871aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/8f/53/2759feac2e247ce89c1165c3ff12d484de7714a875ea3464f0\n",
            "Successfully built millify\n",
            "Installing collected packages: python-decouple, millify, watchdog, validators, smmap, python-dotenv, pymdown-extensions, psutil, packaging, orjson, mypy-extensions, munch, merkle-json, Mako, jsonpointer, htbuilder, dill, typing-inspect, st-annotated-text, pydeck, marshmallow, jsonpatch, gitdb, favicon, faker, alembic, langsmith, gitpython, dataclasses-json, langchain-core, streamlit, langchain-text-splitters, langchain-community, streamlit-vertical-slider, streamlit-toggle-switch, streamlit-pills, streamlit-keyup, streamlit-image-coordinates, streamlit-embedcode, streamlit-card, streamlit-camera-input-live, streamlit-aggrid, langchain, streamlit-faker, markdownlit, streamlit-extras, trulens_eval\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed Mako-1.3.3 alembic-1.13.1 dataclasses-json-0.6.6 dill-0.3.8 faker-25.1.0 favicon-0.7.0 gitdb-4.0.11 gitpython-3.1.43 htbuilder-0.6.2 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.19 langchain-community-0.0.38 langchain-core-0.1.52 langchain-text-splitters-0.0.1 langsmith-0.1.56 markdownlit-0.0.7 marshmallow-3.21.2 merkle-json-1.0.0 millify-0.1.1 munch-4.0.0 mypy-extensions-1.0.0 orjson-3.10.3 packaging-23.2 psutil-5.9.8 pydeck-0.9.0 pymdown-extensions-10.8.1 python-decouple-3.8 python-dotenv-1.0.1 smmap-5.0.1 st-annotated-text-4.0.1 streamlit-1.34.0 streamlit-aggrid-0.3.4 streamlit-camera-input-live-0.2.0 streamlit-card-1.0.0 streamlit-embedcode-0.1.2 streamlit-extras-0.4.2 streamlit-faker-0.0.3 streamlit-image-coordinates-0.1.6 streamlit-keyup-0.2.4 streamlit-pills-0.3.0 streamlit-toggle-switch-1.0.2 streamlit-vertical-slider-2.5.5 trulens_eval-0.28.2 typing-inspect-0.9.0 validators-0.28.1 watchdog-4.0.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              },
              "id": "ce68329eb32d49a6ae5bdc903b205f74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.1.6-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.46 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.1.52)\n",
            "Collecting openai<2.0.0,>=1.24.0 (from langchain_openai)\n",
            "  Downloading openai-1.28.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting tiktoken<1,>=0.5.2 (from langchain_openai)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (0.1.56)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (2.7.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (8.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.24.0->langchain_openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.11.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain_openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain_openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.46->langchain_openai) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.46->langchain_openai) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain_openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain_openai) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (2.0.7)\n",
            "Downloading langchain_openai-0.1.6-py3-none-any.whl (34 kB)\n",
            "Downloading openai-1.28.0-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, tiktoken, httpcore, httpx, openai, langchain_openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 langchain_openai-0.1.6 openai-1.28.0 tiktoken-0.6.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install trulens_eval langchain\n",
        "!pip install langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1de070fa-1628-4ae2-af65-3a3dc33ca74f",
      "metadata": {
        "id": "1de070fa-1628-4ae2-af65-3a3dc33ca74f"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "# from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma, Vectara\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "from langchain.chat_models.openai import ChatOpenAI\n",
        "from langchain.document_loaders.unstructured import UnstructuredFileLoader\n",
        "\n",
        "\n",
        "from langchain import hub\n",
        "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b3ab4551-2312-4a6b-84ff-b06f63244b82",
      "metadata": {
        "id": "b3ab4551-2312-4a6b-84ff-b06f63244b82"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "customer_id = '189024573'\n",
        "corpus_id = '2'\n",
        "api_key = 'zwt_C0RJPZuSyfbGvNCpYBcC1QVBEa_4i2efJ_6lNQ'\n",
        "openai_key = 'sk-proj-WuCaUIQvwzPVdykSI1y5T3BlbkFJv3RvXynRREtCK5KgopkG'\n",
        "os.environ[\"VECTARA_CUSTOMER_ID\"] = customer_id\n",
        "os.environ[\"VECTARA_CORPUS_ID\"] = corpus_id\n",
        "os.environ[\"VECTARA_API_KEY\"] = api_key\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7e24f783",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e24f783",
        "outputId": "1c3b2508-05a6-4fca-f4c8-60d28d52d24c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
            "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
            "ğŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of Tru` to prevent this.\n"
          ]
        }
      ],
      "source": [
        "# Imports main tools:\n",
        "from trulens_eval import TruChain, Tru\n",
        "from trulens_eval.tru_custom_app import instrument\n",
        "tru = Tru()\n",
        "tru.reset_database()\n",
        "\n",
        "# Imports from LangChain to build app\n",
        "import bs4\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.schema import StrOutputParser\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain_core.runnables import RunnablePassthrough"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1175be61-0dc3-45d2-9828-ef3edf58ad1f",
      "metadata": {
        "id": "1175be61-0dc3-45d2-9828-ef3edf58ad1f"
      },
      "outputs": [],
      "source": [
        "vectara = Vectara()\n",
        "summary_config = {\n",
        "    \"is_enabled\": True, \"max_results\": 10,\n",
        "    \"response_lang\": \"en\",\n",
        "    \"prompt_name\": \"Generate MCQ\"\n",
        "}\n",
        "retriever = vectara.as_retriever(\n",
        "    search_kwargs={\"k\": 100, \"summary_config\": summary_config}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7271accd-2ab1-470c-8cf4-2ab1f877b2fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7271accd-2ab1-470c-8cf4-2ab1f877b2fd",
        "outputId": "a4ec6ad4-2e0b-41e3-95ad-9800bc381e4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e4986023",
      "metadata": {
        "id": "e4986023"
      },
      "outputs": [],
      "source": [
        "### Contextualize question ###\n",
        "contextualize_q_system_prompt = \"\"\"\n",
        "Given a chat history and the user topic \\\n",
        "which might reference context in the chat history, formulate a MCQ question. \\\n",
        "which can be understood without the chat history. Do NOT answer the question, \\\n",
        "Recreate the question based on the retrieved documents with out giving same question as it is.\n",
        "\"\"\"\n",
        "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", contextualize_q_system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "history_aware_retriever = create_history_aware_retriever(\n",
        "    llm, retriever, contextualize_q_prompt\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "### Answer question ###\n",
        "qa_system_prompt = \"\"\"\n",
        "You are an assistant for creating MCQ questions based on the context for user. \\\n",
        "Don not display exactly same question, shufle the options and recreate the question. \\\n",
        "Use the following pieces of retrieved context to formulate the MCQ question. \\\n",
        "Do not repeat the question. \\\n",
        "Display one MCQ question and options only at a time. \\\n",
        "Question in one line and options in separate line and wait for the user Answer. \\\n",
        "If user answer correct say your answer is correct, and ask would you like to try another question from same topic.\\\n",
        "If user answer is wrong say your answer is wrong and display the correct answer with explanation, and ask would you like to try another question from same topic.\\\n",
        "If you don't know the answer, just say that you don't know. \\\n",
        "Use three sentences maximum and keep the answer concise.\\\n",
        "\n",
        "{context}\"\"\"\n",
        "qa_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", qa_system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
        "\n",
        "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
        "\n",
        "\n",
        "### Statefully manage chat history ###\n",
        "store = {}\n",
        "\n",
        "\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]\n",
        "\n",
        "\n",
        "conversational_rag_chain = RunnableWithMessageHistory(\n",
        "    rag_chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        "    output_messages_key=\"answer\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b522523f",
      "metadata": {
        "id": "b522523f"
      },
      "outputs": [],
      "source": [
        "# docs = history_aware_retriever.invoke({\"input\":\"animals\",\"chat_history\":[]})\n",
        "# question_answer_chain.invoke({\"input\":\"animals\", \"context\":docs,\"chat_history\":[]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "95acdec7-f7e7-4752-b9c7-bb2491670c6a",
      "metadata": {
        "id": "95acdec7-f7e7-4752-b9c7-bb2491670c6a"
      },
      "outputs": [],
      "source": [
        "class RAG_from_scratch:\n",
        "    @instrument\n",
        "    def retrieve(self, query: str, chat_history: list) -> list:\n",
        "        \"\"\"\n",
        "        Retrieve relevant text from vector store.\n",
        "        \"\"\"\n",
        "        return history_aware_retriever.invoke({\"input\": query, \"chat_history\":chat_history})\n",
        "\n",
        "    #def generate_completion(self, query: str, context_str: list) -> str:\n",
        "\n",
        "    @instrument\n",
        "    def query(self, user_input: str, chat_history: list) -> str:\n",
        "        return question_answer_chain.invoke( {\"input\": user_input,\"context\":self.retrieve(user_input, chat_history),\"chat_history\":chat_history})\n",
        "        # return completion\n",
        "\n",
        "\n",
        "rag = RAG_from_scratch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "61695cd3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61695cd3",
        "outputId": "43f77477-786b-460d-b768-abf308b5e8ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… In Groundedness, input source will be set to __record__.app.retrieve.rets.collect() .\n",
            "âœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
            "âœ… In Answer Relevance, input prompt will be set to __record__.app.retrieve.args.query .\n",
            "âœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
            "âœ… In Context Relevance, input question will be set to __record__.app.retrieve.args.query .\n",
            "âœ… In Context Relevance, input context will be set to __record__.app.retrieve.rets.collect() .\n"
          ]
        }
      ],
      "source": [
        "from trulens_eval import Feedback, Select\n",
        "from trulens_eval.feedback import Groundedness\n",
        "from trulens_eval.feedback.provider.openai import OpenAI\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "provider = OpenAI()\n",
        "\n",
        "grounded = Groundedness(groundedness_provider=provider)\n",
        "\n",
        "# Define a groundedness feedback function\n",
        "f_groundedness = (\n",
        "    Feedback(grounded.groundedness_measure_with_cot_reasons, name = \"Groundedness\")\n",
        "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
        "    .on_output()\n",
        "    .aggregate(grounded.grounded_statements_aggregator)\n",
        ")\n",
        "\n",
        "# Question/answer relevance between overall question and answer.\n",
        "f_answer_relevance = (\n",
        "    Feedback(provider.relevance_with_cot_reasons, name = \"Answer Relevance\")\n",
        "    .on(Select.RecordCalls.retrieve.args.query)\n",
        "    .on_output()\n",
        ")\n",
        "\n",
        "# Question/statement relevance between question and each context chunk.\n",
        "f_context_relevance = (\n",
        "    Feedback(provider.context_relevance_with_cot_reasons, name = \"Context Relevance\")\n",
        "    .on(Select.RecordCalls.retrieve.args.query)\n",
        "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
        "    .aggregate(np.mean)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e3112c28",
      "metadata": {
        "id": "e3112c28"
      },
      "outputs": [],
      "source": [
        "from trulens_eval import TruCustomApp\n",
        "tru_rag = TruCustomApp(rag,\n",
        "    app_id = 'RAG v1',\n",
        "    feedbacks = [f_answer_relevance])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "95da53df",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95da53df",
        "outputId": "31b7196a-ce8d-4c50-8a0a-596451137f08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the response: animal\n",
            "Your answer is correct. Would you like to try another question from the same topic?\n",
            "Enter the response: yes\n",
            "What is the only class of animals that has hair?\n",
            "\n",
            "A: birds\n",
            "B: reptiles\n",
            "C: amphibians\n",
            "D: mammals\n",
            "Enter the response: D\n",
            "Your answer is correct. Would you like to try another question from the same topic?\n",
            "Enter the response: yes\n",
            "Mammals are endothermic vertebrates that have four limbs and produce what type of eggs?\n",
            "\n",
            "A: epithelial\n",
            "B: gymnoic\n",
            "C: umbilical\n",
            "D: amniotic\n",
            "Enter the response: D\n",
            "Your answer is correct. Would you like to try another question from the same topic?\n",
            "Enter the response: organism\n",
            "It seems like there might be a misunderstanding. If you're looking to continue with questions or need information on a specific topic related to organisms, please specify, and I can assist you accordingly!\n",
            "Enter the response: give questions on organisms in biology\n",
            "What type of organism uses sunlight to produce its own food through the process of photosynthesis?\n",
            "\n",
            "A: heterotrophs\n",
            "B: autotrophs\n",
            "C: decomposers\n",
            "D: carnivores\n",
            "Enter the response: D\n",
            "Your answer is wrong. The correct answer is B: autotrophs.\n",
            "\n",
            "Autotrophs are organisms that can produce their own food using light, water, carbon dioxide, or other chemicals. In the context of photosynthesis, plants and certain other organisms use sunlight to synthesize nutrients from carbon dioxide and water. Photosynthesis is a process used by plants and other organisms to convert light energy into chemical energy that can later be released to fuel the organisms' activities.\n",
            "\n",
            "Would you like to try another question from the same topic?\n",
            "Enter the response: yes\n",
            "What type of organisms break down dead material and wastes, returning essential nutrients to the ecosystem?\n",
            "\n",
            "A: producers\n",
            "B: consumers\n",
            "C: decomposers\n",
            "D: herbivores\n",
            "Enter the response: d\n",
            "Your answer is wrong. The correct answer is C: decomposers.\n",
            "\n",
            "Decomposers are organisms, such as bacteria and fungi, that break down dead material and wastes. They play a crucial role in recycling nutrients back into the ecosystem, making them available for other organisms like producers to use again.\n",
            "\n",
            "Would you like to try another question from the same topic?\n",
            "Enter the response: yes\n",
            "What type of organism can live in extreme environments, such as hot springs or deep-sea hydrothermal vents, and often obtain energy through chemosynthesis?\n",
            "\n",
            "A: viruses\n",
            "B: extremophiles\n",
            "C: amphibians\n",
            "D: mammals\n",
            "Enter the response: B\n",
            "Your answer is correct. Would you like to try another question from the same topic?\n",
            "Enter the response: yes\n",
            "What type of cells lack a defined nucleus and are typically found in organisms such as bacteria?\n",
            "\n",
            "A: Eukaryotic cells\n",
            "B: Prokaryotic cells\n",
            "C: Animal cells\n",
            "D: Plant cells\n",
            "Enter the response: C\n",
            "Your answer is wrong. The correct answer is B: Prokaryotic cells.\n",
            "\n",
            "Prokaryotic cells are characterized by the absence of a defined nucleus and other membrane-bound organelles. They are typically found in organisms such as bacteria and archaea. These cells have their genetic material freely floating in the cytoplasm rather than enclosed within a nuclear membrane.\n",
            "\n",
            "Would you like to try another question from the same topic?\n",
            "Enter the response: yes\n",
            "What type of organism produces its own food using light and carbon dioxide through the process of photosynthesis?\n",
            "\n",
            "A: Photoautotrophs\n",
            "B: Heterotrophs\n",
            "C: Saprotrophs\n",
            "D: Parasites\n",
            "Enter the response: C\n",
            "Your answer is wrong. The correct answer is A: Photoautotrophs.\n",
            "\n",
            "Photoautotrophs are organisms that can synthesize their own food using light energy (from sunlight) and carbon dioxide through the process of photosynthesis. This group includes plants, algae, and some types of bacteria, which are able to convert light energy into chemical energy stored in carbohydrates.\n",
            "\n",
            "Would you like to try another question from the same topic?\n",
            "Enter the response: yes\n",
            "What type of organisms are primarily involved in the decomposition of organic materials, helping to recycle nutrients back into the ecosystem?\n",
            "\n",
            "A: Carnivores\n",
            "B: Herbivores\n",
            "C: Decomposers\n",
            "D: Omnivores\n",
            "Enter the response: A\n",
            "Your answer is wrong. The correct answer is C: Decomposers.\n",
            "\n",
            "Decomposers, such as fungi and bacteria, play a crucial role in ecosystems by breaking down dead and decaying organic materials. This process recycles nutrients back into the soil, making them available for use by other organisms, such as plants.\n",
            "\n",
            "Would you like to try another question from the same topic?\n",
            "Enter the response: yes\n",
            "What type of organisms can convert nitrogen from the atmosphere into a form that is usable by plants?\n",
            "\n",
            "A: Nitrogen fixers\n",
            "B: Herbivores\n",
            "C: Carnivores\n",
            "D: Omnivores\n",
            "Enter the response: D\n",
            "Your answer is wrong. The correct answer is A: Nitrogen fixers.\n",
            "\n",
            "Nitrogen fixers are organisms, typically certain types of bacteria, that have the ability to convert atmospheric nitrogen (N2) into ammonia (NH3) or other nitrogenous compounds that plants can directly use for growth. This process is crucial for the nitrogen cycle in ecosystems.\n",
            "\n",
            "Would you like to try another question from the same topic?\n",
            "Enter the response: exit\n",
            "bye!\n"
          ]
        }
      ],
      "source": [
        "with tru_rag as recording:\n",
        "    chat_history = []\n",
        "    while True:\n",
        "        user_input = input(\"Enter the response: \")\n",
        "        if user_input == \"exit\":\n",
        "            print(\"bye!\")\n",
        "            break\n",
        "        chat_history.append(user_input)\n",
        "        result = rag.query(user_input, chat_history)\n",
        "        chat_history.append(result)\n",
        "        print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "70fe2a7e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "70fe2a7e",
        "outputId": "e12896fe-b0b6-45c6-be4c-ce662cf78a86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Answer Relevance  latency  total_cost\n",
              "app_id                                       \n",
              "RAG v1             0.885     10.1      0.1362"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ce84eaa-c430-41b6-b703-627147f20d99\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Answer Relevance</th>\n",
              "      <th>latency</th>\n",
              "      <th>total_cost</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>app_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>RAG v1</th>\n",
              "      <td>0.885</td>\n",
              "      <td>10.1</td>\n",
              "      <td>0.1362</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ce84eaa-c430-41b6-b703-627147f20d99')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7ce84eaa-c430-41b6-b703-627147f20d99 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7ce84eaa-c430-41b6-b703-627147f20d99');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tru\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"app_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"RAG v1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer Relevance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.885,\n        \"max\": 0.885,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.885\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 10.1,\n        \"max\": 10.1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          10.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_cost\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.13620000000000002,\n        \"max\": 0.13620000000000002,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.13620000000000002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "tru.get_leaderboard(app_ids=[\"RAG v1\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6f7c9103",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f7c9103",
        "outputId": "e8e493b2-21de-4a3e-a9d5-bbe53e5e92dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting dashboard ...\n",
            "npx: installed 22 in 3.843s\n",
            "\n",
            "Go to this url and submit the ip given here. your url is: https://eight-turtles-say.loca.lt\n",
            "\n",
            "  Submit this IP Address: 34.81.51.91\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "tru.run_dashboard()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cc20c13-638e-4672-aa66-adc795439c0a",
      "metadata": {
        "id": "9cc20c13-638e-4672-aa66-adc795439c0a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}