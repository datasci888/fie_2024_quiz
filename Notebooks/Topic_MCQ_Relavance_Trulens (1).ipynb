{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d18d190",
      "metadata": {
        "id": "3d18d190"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install trulens_eval langchain\n",
        "!pip install langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1de070fa-1628-4ae2-af65-3a3dc33ca74f",
      "metadata": {
        "id": "1de070fa-1628-4ae2-af65-3a3dc33ca74f"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "# from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma, Vectara\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "from langchain.chat_models.openai import ChatOpenAI\n",
        "from langchain.document_loaders.unstructured import UnstructuredFileLoader\n",
        "\n",
        "\n",
        "from langchain import hub\n",
        "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b3ab4551-2312-4a6b-84ff-b06f63244b82",
      "metadata": {
        "id": "b3ab4551-2312-4a6b-84ff-b06f63244b82"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "customer_id = '189024573'\n",
        "corpus_id = '2'\n",
        "\n",
        "os.environ[\"VECTARA_CUSTOMER_ID\"] = customer_id\n",
        "os.environ[\"VECTARA_CORPUS_ID\"] = corpus_id\n",
        "os.environ[\"VECTARA_API_KEY\"] = api_key\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7e24f783",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e24f783",
        "outputId": "1c3b2508-05a6-4fca-f4c8-60d28d52d24c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
            "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
            "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of Tru` to prevent this.\n"
          ]
        }
      ],
      "source": [
        "# Imports main tools:\n",
        "from trulens_eval import TruChain, Tru\n",
        "from trulens_eval.tru_custom_app import instrument\n",
        "tru = Tru()\n",
        "tru.reset_database()\n",
        "\n",
        "# Imports from LangChain to build app\n",
        "import bs4\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.schema import StrOutputParser\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain_core.runnables import RunnablePassthrough"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1175be61-0dc3-45d2-9828-ef3edf58ad1f",
      "metadata": {
        "id": "1175be61-0dc3-45d2-9828-ef3edf58ad1f"
      },
      "outputs": [],
      "source": [
        "vectara = Vectara()\n",
        "summary_config = {\n",
        "    \"is_enabled\": True, \"max_results\": 10,\n",
        "    \"response_lang\": \"en\",\n",
        "    \"prompt_name\": \"Generate MCQ\"\n",
        "}\n",
        "retriever = vectara.as_retriever(\n",
        "    search_kwargs={\"k\": 100, \"summary_config\": summary_config}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7271accd-2ab1-470c-8cf4-2ab1f877b2fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7271accd-2ab1-470c-8cf4-2ab1f877b2fd",
        "outputId": "a4ec6ad4-2e0b-41e3-95ad-9800bc381e4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e4986023",
      "metadata": {
        "id": "e4986023"
      },
      "outputs": [],
      "source": [
        "### Contextualize question ###\n",
        "contextualize_q_system_prompt = \"\"\"\n",
        "Given a chat history and the user topic \\\n",
        "which might reference context in the chat history, formulate a MCQ question. \\\n",
        "which can be understood without the chat history. Do NOT answer the question, \\\n",
        "Recreate the question based on the retrieved documents with out giving same question as it is.\n",
        "\"\"\"\n",
        "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", contextualize_q_system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "history_aware_retriever = create_history_aware_retriever(\n",
        "    llm, retriever, contextualize_q_prompt\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "### Answer question ###\n",
        "qa_system_prompt = \"\"\"\n",
        "You are an assistant for creating MCQ questions based on the context for user. \\\n",
        "Don not display exactly same question, shufle the options and recreate the question. \\\n",
        "Use the following pieces of retrieved context to formulate the MCQ question. \\\n",
        "Do not repeat the question. \\\n",
        "Display one MCQ question and options only at a time. \\\n",
        "Question in one line and options in separate line and wait for the user Answer. \\\n",
        "If user answer correct say your answer is correct, and ask would you like to try another question from same topic.\\\n",
        "If user answer is wrong say your answer is wrong and display the correct answer with explanation, and ask would you like to try another question from same topic.\\\n",
        "If you don't know the answer, just say that you don't know. \\\n",
        "Use three sentences maximum and keep the answer concise.\\\n",
        "\n",
        "{context}\"\"\"\n",
        "qa_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", qa_system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
        "\n",
        "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
        "\n",
        "\n",
        "### Statefully manage chat history ###\n",
        "store = {}\n",
        "\n",
        "\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]\n",
        "\n",
        "\n",
        "conversational_rag_chain = RunnableWithMessageHistory(\n",
        "    rag_chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        "    output_messages_key=\"answer\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b522523f",
      "metadata": {
        "id": "b522523f"
      },
      "outputs": [],
      "source": [
        "# docs = history_aware_retriever.invoke({\"input\":\"animals\",\"chat_history\":[]})\n",
        "# question_answer_chain.invoke({\"input\":\"animals\", \"context\":docs,\"chat_history\":[]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "95acdec7-f7e7-4752-b9c7-bb2491670c6a",
      "metadata": {
        "id": "95acdec7-f7e7-4752-b9c7-bb2491670c6a"
      },
      "outputs": [],
      "source": [
        "class RAG_from_scratch:\n",
        "    @instrument\n",
        "    def retrieve(self, query: str, chat_history: list) -> list:\n",
        "        \"\"\"\n",
        "        Retrieve relevant text from vector store.\n",
        "        \"\"\"\n",
        "        return history_aware_retriever.invoke({\"input\": query, \"chat_history\":chat_history})\n",
        "\n",
        "    #def generate_completion(self, query: str, context_str: list) -> str:\n",
        "\n",
        "    @instrument\n",
        "    def query(self, user_input: str, chat_history: list) -> str:\n",
        "        return question_answer_chain.invoke( {\"input\": user_input,\"context\":self.retrieve(user_input, chat_history),\"chat_history\":chat_history})\n",
        "        # return completion\n",
        "\n",
        "\n",
        "rag = RAG_from_scratch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "61695cd3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61695cd3",
        "outputId": "43f77477-786b-460d-b768-abf308b5e8ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… In Groundedness, input source will be set to __record__.app.retrieve.rets.collect() .\n",
            "âœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
            "âœ… In Answer Relevance, input prompt will be set to __record__.app.retrieve.args.query .\n",
            "âœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
            "âœ… In Context Relevance, input question will be set to __record__.app.retrieve.args.query .\n",
            "âœ… In Context Relevance, input context will be set to __record__.app.retrieve.rets.collect() .\n"
          ]
        }
      ],
      "source": [
        "from trulens_eval import Feedback, Select\n",
        "from trulens_eval.feedback import Groundedness\n",
        "from trulens_eval.feedback.provider.openai import OpenAI\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "provider = OpenAI()\n",
        "\n",
        "grounded = Groundedness(groundedness_provider=provider)\n",
        "\n",
        "# Define a groundedness feedback function\n",
        "f_groundedness = (\n",
        "    Feedback(grounded.groundedness_measure_with_cot_reasons, name = \"Groundedness\")\n",
        "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
        "    .on_output()\n",
        "    .aggregate(grounded.grounded_statements_aggregator)\n",
        ")\n",
        "\n",
        "# Question/answer relevance between overall question and answer.\n",
        "f_answer_relevance = (\n",
        "    Feedback(provider.relevance_with_cot_reasons, name = \"Answer Relevance\")\n",
        "    .on(Select.RecordCalls.retrieve.args.query)\n",
        "    .on_output()\n",
        ")\n",
        "\n",
        "# Question/statement relevance between question and each context chunk.\n",
        "f_context_relevance = (\n",
        "    Feedback(provider.context_relevance_with_cot_reasons, name = \"Context Relevance\")\n",
        "    .on(Select.RecordCalls.retrieve.args.query)\n",
        "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
        "    .aggregate(np.mean)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e3112c28",
      "metadata": {
        "id": "e3112c28"
      },
      "outputs": [],
      "source": [
        "from trulens_eval import TruCustomApp\n",
        "tru_rag = TruCustomApp(rag,\n",
        "    app_id = 'RAG v1',\n",
        "    feedbacks = [f_answer_relevance])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "95da53df",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95da53df",
        "outputId": "31b7196a-ce8d-4c50-8a0a-596451137f08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the response: animal\n",
            "Your answer is correct. Would you like to try another question from the same topic?\n",
            "Enter the response: yes\n",
            "What is the only class of animals that has hair?\n",
            "\n",
            "A: birds\n",
            "B: reptiles\n",
            "C: amphibians\n",
            "D: mammals\n",
            "Enter the response: D\n",
            "Your answer is correct. Would you like to try another question from the same topic?\n",
            "Enter the response: yes\n",
            "Mammals are endothermic vertebrates that have four limbs and produce what type of eggs?\n",
            "\n",
            "A: epithelial\n",
            "B: gymnoic\n",
            "C: umbilical\n",
            "D: amniotic\n",
            "Enter the response: D\n",
            "Your answer is correct. Would you like to try another question from the same topic?\n",
            "Enter the response: organism\n",
            "It seems like there might be a misunderstanding. If you're looking to continue with questions or need information on a specific topic related to organisms, please specify, and I can assist you accordingly!\n",
            "Enter the response: give questions on organisms in biology\n",
            "What type of organism uses sunlight to produce its own food through the process of photosynthesis?\n",
            "\n",
            "A: heterotrophs\n",
            "B: autotrophs\n",
            "C: decomposers\n",
            "D: carnivores\n",
            "Enter the response: D\n",
            "Your answer is wrong. The correct answer is B: autotrophs.\n",
            "\n",
            "Autotrophs are organisms that can produce their own food using light, water, carbon dioxide, or other chemicals. In the context of photosynthesis, plants and certain other organisms use sunlight to synthesize nutrients from carbon dioxide and water. Photosynthesis is a process used by plants and other organisms to convert light energy into chemical energy that can later be released to fuel the organisms' activities.\n",
            "\n",
            "Would you like to try another question from the same topic?\n",
            "Enter the response: yes\n",
            "What type of organisms break down dead material and wastes, returning essential nutrients to the ecosystem?\n",
            "\n",
            "A: producers\n",
            "B: consumers\n",
            "C: decomposers\n",
            "D: herbivores\n",
            "Enter the response: d\n",
            "Your answer is wrong. The correct answer is C: decomposers.\n",
            "\n",
            "Decomposers are organisms, such as bacteria and fungi, that break down dead material and wastes. They play a crucial role in recycling nutrients back into the ecosystem, making them available for other organisms like producers to use again.\n",
            "\n",
            "Would you like to try another question from the same topic?\n",
            "Enter the response: yes\n",
            "What type of organism can live in extreme environments, such as hot springs or deep-sea hydrothermal vents, and often obtain energy through chemosynthesis?\n",
            "\n",
            "A: viruses\n",
            "B: extremophiles\n",
            "C: amphibians\n",
            "D: mammals\n",
            "Enter the response: B\n",
            "Your answer is correct. Would you like to try another question from the same topic?\n",
            "Enter the response: yes\n",
            "What type of cells lack a defined nucleus and are typically found in organisms such as bacteria?\n",
            "\n",
            "A: Eukaryotic cells\n",
            "B: Prokaryotic cells\n",
            "C: Animal cells\n",
            "D: Plant cells\n",
            "Enter the response: C\n",
            "Your answer is wrong. The correct answer is B: Prokaryotic cells.\n",
            "\n",
            "Prokaryotic cells are characterized by the absence of a defined nucleus and other membrane-bound organelles. They are typically found in organisms such as bacteria and archaea. These cells have their genetic material freely floating in the cytoplasm rather than enclosed within a nuclear membrane.\n",
            "\n",
            "Would you like to try another question from the same topic?\n",
            "Enter the response: yes\n",
            "What type of organism produces its own food using light and carbon dioxide through the process of photosynthesis?\n",
            "\n",
            "A: Photoautotrophs\n",
            "B: Heterotrophs\n",
            "C: Saprotrophs\n",
            "D: Parasites\n",
            "Enter the response: C\n",
            "Your answer is wrong. The correct answer is A: Photoautotrophs.\n",
            "\n",
            "Photoautotrophs are organisms that can synthesize their own food using light energy (from sunlight) and carbon dioxide through the process of photosynthesis. This group includes plants, algae, and some types of bacteria, which are able to convert light energy into chemical energy stored in carbohydrates.\n",
            "\n",
            "Would you like to try another question from the same topic?\n",
            "Enter the response: yes\n",
            "What type of organisms are primarily involved in the decomposition of organic materials, helping to recycle nutrients back into the ecosystem?\n",
            "\n",
            "A: Carnivores\n",
            "B: Herbivores\n",
            "C: Decomposers\n",
            "D: Omnivores\n",
            "Enter the response: A\n",
            "Your answer is wrong. The correct answer is C: Decomposers.\n",
            "\n",
            "Decomposers, such as fungi and bacteria, play a crucial role in ecosystems by breaking down dead and decaying organic materials. This process recycles nutrients back into the soil, making them available for use by other organisms, such as plants.\n",
            "\n",
            "Would you like to try another question from the same topic?\n",
            "Enter the response: yes\n",
            "What type of organisms can convert nitrogen from the atmosphere into a form that is usable by plants?\n",
            "\n",
            "A: Nitrogen fixers\n",
            "B: Herbivores\n",
            "C: Carnivores\n",
            "D: Omnivores\n",
            "Enter the response: D\n",
            "Your answer is wrong. The correct answer is A: Nitrogen fixers.\n",
            "\n",
            "Nitrogen fixers are organisms, typically certain types of bacteria, that have the ability to convert atmospheric nitrogen (N2) into ammonia (NH3) or other nitrogenous compounds that plants can directly use for growth. This process is crucial for the nitrogen cycle in ecosystems.\n",
            "\n",
            "Would you like to try another question from the same topic?\n",
            "Enter the response: exit\n",
            "bye!\n"
          ]
        }
      ],
      "source": [
        "with tru_rag as recording:\n",
        "    chat_history = []\n",
        "    while True:\n",
        "        user_input = input(\"Enter the response: \")\n",
        "        if user_input == \"exit\":\n",
        "            print(\"bye!\")\n",
        "            break\n",
        "        chat_history.append(user_input)\n",
        "        result = rag.query(user_input, chat_history)\n",
        "        chat_history.append(result)\n",
        "        print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "70fe2a7e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "70fe2a7e",
        "outputId": "e12896fe-b0b6-45c6-be4c-ce662cf78a86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Answer Relevance  latency  total_cost\n",
              "app_id                                       \n",
              "RAG v1             0.885     10.1      0.1362"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ce84eaa-c430-41b6-b703-627147f20d99\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Answer Relevance</th>\n",
              "      <th>latency</th>\n",
              "      <th>total_cost</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>app_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>RAG v1</th>\n",
              "      <td>0.885</td>\n",
              "      <td>10.1</td>\n",
              "      <td>0.1362</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ce84eaa-c430-41b6-b703-627147f20d99')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7ce84eaa-c430-41b6-b703-627147f20d99 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7ce84eaa-c430-41b6-b703-627147f20d99');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tru\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"app_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"RAG v1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer Relevance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.885,\n        \"max\": 0.885,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.885\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 10.1,\n        \"max\": 10.1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          10.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_cost\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.13620000000000002,\n        \"max\": 0.13620000000000002,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.13620000000000002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "tru.get_leaderboard(app_ids=[\"RAG v1\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6f7c9103",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f7c9103",
        "outputId": "e8e493b2-21de-4a3e-a9d5-bbe53e5e92dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting dashboard ...\n",
            "npx: installed 22 in 3.843s\n",
            "\n",
            "Go to this url and submit the ip given here. your url is: https://eight-turtles-say.loca.lt\n",
            "\n",
            "  Submit this IP Address: 34.81.51.91\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "tru.run_dashboard()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cc20c13-638e-4672-aa66-adc795439c0a",
      "metadata": {
        "id": "9cc20c13-638e-4672-aa66-adc795439c0a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}