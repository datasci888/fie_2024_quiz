{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade pip\n",
        "# !pip install trulens_eval langchain\n",
        "# !pip install langchain_openai"
      ],
      "metadata": {
        "id": "Uf_9BQ9yL0I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5IH_IS0sLu_b"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "# from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma, Vectara\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "from langchain.chat_models.openai import ChatOpenAI\n",
        "from langchain.document_loaders.unstructured import UnstructuredFileLoader\n",
        "\n",
        "\n",
        "from langchain import hub\n",
        "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0kv5zHgTLu_d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "customer_id = ''\n",
        "corpus_id = '2'\n",
        "api_key = ''\n",
        "openai_key = 'sk-proj-'\n",
        "os.environ[\"VECTARA_CUSTOMER_ID\"] = customer_id\n",
        "os.environ[\"VECTARA_CORPUS_ID\"] = corpus_id\n",
        "os.environ[\"VECTARA_API_KEY\"] = api_key\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mS8SZUBLu_d",
        "outputId": "e0e5f757-50a6-497e-8cd5-ff5d12acb06d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
            "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
            "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of Tru` to prevent this.\n"
          ]
        }
      ],
      "source": [
        "# Imports main tools:\n",
        "from trulens_eval import TruChain, Tru\n",
        "tru = Tru()\n",
        "tru.reset_database()\n",
        "\n",
        "# Imports from LangChain to build app\n",
        "import bs4\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.schema import StrOutputParser\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain_core.runnables import RunnablePassthrough"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QTE1lGdoLu_e"
      },
      "outputs": [],
      "source": [
        "vectara = Vectara()\n",
        "summary_config = {\n",
        "    \"is_enabled\": True, \"max_results\": 30,\n",
        "    \"response_lang\": \"en\",\n",
        "    \"prompt_name\": \"Chatbot Q&A\"\n",
        "}\n",
        "retriever = vectara.as_retriever(\n",
        "    search_kwargs={\"k\": 100, \"summary_config\": summary_config}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOIRSfFYLu_f",
        "outputId": "6877e9ab-92f2-421e-f98d-9097f59fec9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. \\\n",
        "Display the Answer in separate line \\\n",
        "If you don't know the answer, just say that you don't know. \\\n",
        "Use three sentences maximum and keep the answer concise.\\\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Answer:\n",
        "\n",
        "Explanation:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "custom_rag_prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | custom_rag_prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "T8vI8O2oLu_f"
      },
      "outputs": [],
      "source": [
        "result = rag_chain.invoke(\"What is endocrine diseage?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7mBHx-JLu_f",
        "outputId": "0eaf5f09-5c04-4c54-e2cf-7fbe432fab84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Endocrine disease usually involves the secretion of too much or not enough hormone. When too much hormone is secreted, it is called hypersecretion. When not enough hormone is secreted, it is called hyposecretion.\n"
          ]
        }
      ],
      "source": [
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbRQO8iXLu_f",
        "outputId": "6a936843-18c0-4c38-fcf2-cf80caefe70e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… In groundedness_measure_with_cot_reasons, input source will be set to __record__.app.first.steps__.context.first.get_relevant_documents.rets.collect() .\n",
            "âœ… In groundedness_measure_with_cot_reasons, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
            "âœ… In relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
            "âœ… In relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
            "âœ… In context_relevance_with_cot_reasons, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
            "âœ… In context_relevance_with_cot_reasons, input context will be set to __record__.app.first.steps__.context.first.get_relevant_documents.rets .\n"
          ]
        }
      ],
      "source": [
        "from trulens_eval.feedback.provider import OpenAI\n",
        "from trulens_eval import Feedback\n",
        "import numpy as np\n",
        "\n",
        "# Initialize provider class\n",
        "provider = OpenAI()\n",
        "\n",
        "# select context to be used in feedback. the location of context is app specific.\n",
        "from trulens_eval.app import App\n",
        "context = App.select_context(rag_chain)\n",
        "\n",
        "from trulens_eval.feedback import Groundedness\n",
        "grounded = Groundedness(groundedness_provider=OpenAI())\n",
        "# Define a groundedness feedback function\n",
        "f_groundedness = (\n",
        "    Feedback(grounded.groundedness_measure_with_cot_reasons)\n",
        "    .on(context.collect()) # collect context chunks into a list\n",
        "    .on_output()\n",
        "    .aggregate(grounded.grounded_statements_aggregator)\n",
        ")\n",
        "\n",
        "# Question/answer relevance between overall question and answer.\n",
        "f_answer_relevance = (\n",
        "    Feedback(provider.relevance)\n",
        "    .on_input_output()\n",
        ")\n",
        "# Question/statement relevance between question and each context chunk.\n",
        "f_context_relevance = (\n",
        "    Feedback(provider.context_relevance_with_cot_reasons)\n",
        "    .on_input()\n",
        "    .on(context)\n",
        "    .aggregate(np.mean)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VjievKkaLu_g"
      },
      "outputs": [],
      "source": [
        "tru_recorder = TruChain(rag_chain,\n",
        "    app_id='Q&A_ChatApplication',\n",
        "    feedbacks=[f_answer_relevance])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wAD9MPHzLu_g"
      },
      "outputs": [],
      "source": [
        "q_list = [\"Renal plasma flow equals the blood flow per minute times the what?\",\n",
        "          \"What species do humans belong to?\",\n",
        "          \"Titration is a method to determine what in acids or bases?\",\n",
        "          \"How many different amino acids make up proteins?\",\n",
        "          \"What renewable energy source converts energy from the sunlight into electricity?\",\n",
        "          \"The bones of the skull are connected by what type of joints?\",\n",
        "          \"What is the lowest layer of the atmosphere?\",\n",
        "          \"What is the name of the type of plant tissue consisting of undifferentiated cells that can continue to divide and differentiate?\",\n",
        "          \"What type of organism is commonly used in preparation of foods such as cheese and yogurt?\",\n",
        "          \"Which radio frequency should you listen to if you want less noise?\",\n",
        "          \"The fossil record shows that this type of event is followed by the evolution of new species to fill the habitats where old species lived?\",\n",
        "          \"Although air can transfer heat rapidly by convection, it is a poor conductor and thus a good what?\",\n",
        "          \"What does erosion do to pieces of broken rock?\",\n",
        "          \"While the egg is developing, other changes are taking place in the uterus. it develops a thick lining that is full of what?\",\n",
        "          \"Collagen fibers, elastic fibers, and reticular fibers comprise what type of tissue?\",\n",
        "          \"Surface tension of alveolar fluid, which is mostly water, creates an inward pull of the tissue of what organ?\",\n",
        "          \"What distinguishing characteristic of annelid anatomy shows specialization and adaptation?\",\n",
        "          \"What organ is subdivided into ascending, descending, transverse and sigmoid parts?\",\n",
        "          \"Mushrooms are an example of what type of organism, which includes beneficial and toxic specimens?\",\n",
        "          \"Comparing what sequences provides clues to evolution and development?\",\n",
        "          \"What is the minimum mass capable of supporting sustained fission called?\",\n",
        "          \"Inside the nasal area of the skull, the nasal cavity is divided into halves by the what?\",\n",
        "          \"Bacteria can be chemotrophs, which obtain what by breaking down chemical compounds in their environment?\",\n",
        "          \"What do we call the cartilaginous structure that surrounds the notochrod?\",\n",
        "          \"What is the name for biochemical compounds that consist of one or more chains of small molecules called amino acids?\",\n",
        "          \"In a monogamous pairing, a male individual is generally paired with what other type of individual in a sexual relationship?\",\n",
        "          \"What property of warm air causes it to rise above cold air?\",\n",
        "          \"What organism is characterized by an incomplete digestive system and a single, tentacled opening?\",\n",
        "          \"What term is not the same as energy, but means the energy per unit charge?\",\n",
        "          \"The simplest class of organic compounds is the what?\",\n",
        "          \"The amount of kinetic energy in a moving object depends directly on its mass and what else?\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4ill5O0ALu_g"
      },
      "outputs": [],
      "source": [
        "for q in q_list:\n",
        "    response, tru_record = tru_recorder.with_record(rag_chain.invoke, f\"{q}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "aiUf3WgeLu_g"
      },
      "outputs": [],
      "source": [
        "response, tru_record = tru_recorder.with_record(rag_chain.invoke, \"Fertilization is the union of a sperm and egg, resulting in the formation of what?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "1TvC-Mg-Lu_h",
        "outputId": "0b1a018f-13af-42fb-8e65-187e6d962996"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     relevance  latency  total_cost\n",
              "app_id                                             \n",
              "Q&A_ChatApplication   0.909677   9.4375    0.018386"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de99d127-6498-4146-8183-1ab8b61b5ec1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>relevance</th>\n",
              "      <th>latency</th>\n",
              "      <th>total_cost</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>app_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Q&amp;A_ChatApplication</th>\n",
              "      <td>0.909677</td>\n",
              "      <td>9.4375</td>\n",
              "      <td>0.018386</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de99d127-6498-4146-8183-1ab8b61b5ec1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-de99d127-6498-4146-8183-1ab8b61b5ec1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-de99d127-6498-4146-8183-1ab8b61b5ec1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tru\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"app_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Q&A_ChatApplication\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relevance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9096774193548387,\n        \"max\": 0.9096774193548387,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9096774193548387\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 9.4375,\n        \"max\": 9.4375,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          9.4375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_cost\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.018386484375,\n        \"max\": 0.018386484375,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.018386484375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "tru.get_leaderboard(app_ids=[\"Q&A_ChatApplication\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPWAQzsiLu_h",
        "outputId": "01ccd16d-4489-422d-d646-61508f85863c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting dashboard ...\n",
            "npx: installed 22 in 4.837s\n",
            "\n",
            "Go to this url and submit the ip given here. your url is: https://old-corners-fix.loca.lt\n",
            "\n",
            "  Submit this IP Address: 35.234.41.27\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "tru.run_dashboard()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTZhjzUPLu_h"
      },
      "outputs": [],
      "source": [
        "x"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}